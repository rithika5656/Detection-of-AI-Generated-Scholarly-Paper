{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e44c123",
   "metadata": {},
   "source": [
    "# ü§ñ GenAI Detection Chatbot - Google Colab Version\n",
    "\n",
    "This notebook implements the **AI-Generated Scholarly Paper Detection System** with an **Explainable AI Chatbot**.\n",
    "\n",
    "**Features:**\n",
    "- GenAI Feature Extraction (GPT, Gemini, Claude pattern detection)\n",
    "- Perplexity & Burstiness Analysis\n",
    "- Citation Hallucination Detection\n",
    "- Interactive Explainer Chatbot\n",
    "\n",
    "---\n",
    "**Author:** AI-Generated Scholarly Paper Detection System  \n",
    "**For Academic Use Only**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6370fb9",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b1a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No external dependencies needed! All using Python standard library\n",
    "print(\"‚úÖ All dependencies ready (using Python standard library)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2f7140",
   "metadata": {},
   "source": [
    "## 2. GenAI Feature Extractor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29594ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "\n",
    "class GenAIFeatureExtractor:\n",
    "    \"\"\"\n",
    "    Extracts GenAI-specific linguistic features from scholarly text.\n",
    "    \n",
    "    This class implements detection algorithms for identifying patterns\n",
    "    that are characteristic of AI-generated content from various LLMs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the feature extractor with pattern definitions.\"\"\"\n",
    "        \n",
    "        # GPT-style repetitive phrases\n",
    "        self.gpt_repetitive_patterns = [\n",
    "            r'\\b(in conclusion|to summarize|it is important to note)\\b',\n",
    "            r'\\b(as mentioned (earlier|above|previously))\\b',\n",
    "            r'\\b(this (demonstrates|shows|indicates|suggests) that)\\b',\n",
    "            r'\\b(it (is|can be) (argued|said|noted) that)\\b',\n",
    "            r'\\b(the (fact|idea|concept|notion) that)\\b',\n",
    "            r'\\b(in (this|the) (context|regard|respect))\\b',\n",
    "            r'\\b(plays a (crucial|vital|important|significant|key) role)\\b',\n",
    "            r'\\b(it is worth (noting|mentioning|pointing out))\\b',\n",
    "            r'\\b(one (can|could|might) argue that)\\b',\n",
    "            r'\\b(this (paper|study|research|article) (aims|seeks|attempts))\\b',\n",
    "        ]\n",
    "        \n",
    "        # Claude uncertainty hedging phrases\n",
    "        self.claude_hedging_patterns = [\n",
    "            r'\\b(I think|I believe|I would say|I\\'d suggest)\\b',\n",
    "            r'\\b(perhaps|possibly|potentially|presumably)\\b',\n",
    "            r'\\b(it (seems|appears|looks) (like|as if|that))\\b',\n",
    "            r'\\b(may or may not)\\b',\n",
    "            r'\\b(to some (extent|degree))\\b',\n",
    "            r'\\b(it (could|might|may) be (the case|argued|that))\\b',\n",
    "            r'\\b(there is a possibility that)\\b',\n",
    "            r'\\b(one (possible|potential) (explanation|interpretation))\\b',\n",
    "            r'\\b(this (could|might|may) (suggest|indicate|imply))\\b',\n",
    "            r'\\b(it is (possible|plausible|conceivable) that)\\b',\n",
    "        ]\n",
    "        \n",
    "        # Gemini explanatory overflow patterns\n",
    "        self.gemini_overflow_patterns = [\n",
    "            r'\\b(let me explain|let me clarify|to be more specific)\\b',\n",
    "            r'\\b(in other words|put (simply|differently|another way))\\b',\n",
    "            r'\\b(to (elaborate|expand) (on|further))\\b',\n",
    "            r'\\b(what (this|I) mean(s)? (is|by this))\\b',\n",
    "            r'\\b(essentially|fundamentally|basically)\\b',\n",
    "            r'\\b(for (example|instance)|such as|namely)\\b',\n",
    "            r'\\b(this (is|means|refers to))\\b',\n",
    "            r'\\b(to (understand|grasp|comprehend) this)\\b',\n",
    "            r'\\b((first|second|third)(ly)?[,:]?\\s*(we|one|you))\\b',\n",
    "            r'\\b(it\\'s (important|crucial|essential) to (understand|note|realize))\\b',\n",
    "        ]\n",
    "        \n",
    "        # Suspicious citation patterns (potential hallucinations)\n",
    "        self.suspicious_citation_patterns = [\n",
    "            r'\\((?:Smith|Johnson|Williams|Brown|Jones|Davis|Miller)\\s+et\\s+al\\.\\s*,?\\s*\\d{4}\\)',\n",
    "            r'\\(\\w+\\s+et\\s+al\\.\\s*,?\\s*(2025|2026|2027|2028|2029|2030)\\)',\n",
    "            r'\\((?:Study|Research|Survey|Analysis)\\s+\\d{4}\\)',\n",
    "            r'\\[?\\d+\\]?\\s*(?=\\.|,|;|\\s*$)',\n",
    "            r'\\((?:University|Institute|Organization)\\s+\\d{4}\\)',\n",
    "        ]\n",
    "        \n",
    "    def extract_all_features(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Extract all GenAI features from the given text.\n",
    "        \n",
    "        Args:\n",
    "            text: The scholarly paper text to analyze\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing all extracted features and scores\n",
    "        \"\"\"\n",
    "        if not text or not text.strip():\n",
    "            return self._empty_features()\n",
    "        \n",
    "        # Extract individual features\n",
    "        gpt_score, gpt_details = self.detect_gpt_repetition(text)\n",
    "        gemini_score, gemini_details = self.detect_gemini_overflow(text)\n",
    "        claude_score, claude_details = self.detect_claude_hedging(text)\n",
    "        burstiness_score, burstiness_details = self.calculate_burstiness(text)\n",
    "        citation_score, citation_details = self.detect_citation_hallucination(text)\n",
    "        perplexity_score, perplexity_details = self.estimate_perplexity(text)\n",
    "        \n",
    "        # Calculate composite GenAI score (weighted average)\n",
    "        composite_score = self._calculate_composite_score(\n",
    "            gpt_score, gemini_score, claude_score, \n",
    "            burstiness_score, citation_score, perplexity_score\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'composite_score': round(composite_score, 3),\n",
    "            'features': {\n",
    "                'gpt_repetition': {\n",
    "                    'score': round(gpt_score, 3),\n",
    "                    'details': gpt_details\n",
    "                },\n",
    "                'gemini_overflow': {\n",
    "                    'score': round(gemini_score, 3),\n",
    "                    'details': gemini_details\n",
    "                },\n",
    "                'claude_hedging': {\n",
    "                    'score': round(claude_score, 3),\n",
    "                    'details': claude_details\n",
    "                },\n",
    "                'burstiness': {\n",
    "                    'score': round(burstiness_score, 3),\n",
    "                    'details': burstiness_details\n",
    "                },\n",
    "                'citation_hallucination': {\n",
    "                    'score': round(citation_score, 3),\n",
    "                    'details': citation_details\n",
    "                },\n",
    "                'perplexity': {\n",
    "                    'score': round(perplexity_score, 3),\n",
    "                    'details': perplexity_details\n",
    "                }\n",
    "            },\n",
    "            'interpretation': self._generate_interpretation(\n",
    "                gpt_score, gemini_score, claude_score,\n",
    "                burstiness_score, citation_score, perplexity_score\n",
    "            )\n",
    "        }\n",
    "    \n",
    "    def detect_gpt_repetition(self, text: str) -> Tuple[float, Dict]:\n",
    "        \"\"\"Detect GPT-style repetitive phrase patterns.\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        word_count = len(text.split())\n",
    "        \n",
    "        matches = []\n",
    "        total_matches = 0\n",
    "        \n",
    "        for pattern in self.gpt_repetitive_patterns:\n",
    "            found = re.findall(pattern, text_lower, re.IGNORECASE)\n",
    "            if found:\n",
    "                total_matches += len(found)\n",
    "                matches.extend(found[:3])\n",
    "        \n",
    "        normalized_frequency = (total_matches / max(word_count, 1)) * 1000\n",
    "        score = min(1.0, normalized_frequency / 15)\n",
    "        \n",
    "        return score, {\n",
    "            'matches_found': total_matches,\n",
    "            'examples': matches[:5],\n",
    "            'frequency_per_1000': round(normalized_frequency, 2),\n",
    "            'description': 'GPT-style repetitive phrases detected'\n",
    "        }\n",
    "    \n",
    "    def detect_gemini_overflow(self, text: str) -> Tuple[float, Dict]:\n",
    "        \"\"\"Detect Gemini-style explanatory overflow patterns.\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        word_count = len(text.split())\n",
    "        \n",
    "        matches = []\n",
    "        total_matches = 0\n",
    "        \n",
    "        for pattern in self.gemini_overflow_patterns:\n",
    "            found = re.findall(pattern, text_lower, re.IGNORECASE)\n",
    "            if found:\n",
    "                total_matches += len(found)\n",
    "                matches.extend([str(f) for f in found[:3]])\n",
    "        \n",
    "        normalized_frequency = (total_matches / max(word_count, 1)) * 1000\n",
    "        score = min(1.0, normalized_frequency / 12)\n",
    "        \n",
    "        return score, {\n",
    "            'matches_found': total_matches,\n",
    "            'examples': matches[:5],\n",
    "            'frequency_per_1000': round(normalized_frequency, 2),\n",
    "            'description': 'Over-explanation patterns typical of Gemini'\n",
    "        }\n",
    "    \n",
    "    def detect_claude_hedging(self, text: str) -> Tuple[float, Dict]:\n",
    "        \"\"\"Detect Claude-style uncertainty hedging patterns.\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        word_count = len(text.split())\n",
    "        \n",
    "        matches = []\n",
    "        total_matches = 0\n",
    "        \n",
    "        for pattern in self.claude_hedging_patterns:\n",
    "            found = re.findall(pattern, text_lower, re.IGNORECASE)\n",
    "            if found:\n",
    "                total_matches += len(found)\n",
    "                matches.extend([str(f) for f in found[:3]])\n",
    "        \n",
    "        normalized_frequency = (total_matches / max(word_count, 1)) * 1000\n",
    "        score = min(1.0, normalized_frequency / 10)\n",
    "        \n",
    "        return score, {\n",
    "            'matches_found': total_matches,\n",
    "            'examples': matches[:5],\n",
    "            'frequency_per_1000': round(normalized_frequency, 2),\n",
    "            'description': 'Uncertainty hedging typical of Claude'\n",
    "        }\n",
    "    \n",
    "    def calculate_burstiness(self, text: str) -> Tuple[float, Dict]:\n",
    "        \"\"\"Calculate burstiness (sentence length variance).\"\"\"\n",
    "        sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
    "        \n",
    "        if len(sentences) < 3:\n",
    "            return 0.0, {'variance': 0, 'mean_length': 0, 'description': 'Insufficient sentences'}\n",
    "        \n",
    "        lengths = [len(s.split()) for s in sentences]\n",
    "        mean_len = sum(lengths) / len(lengths)\n",
    "        variance = sum((l - mean_len) ** 2 for l in lengths) / len(lengths)\n",
    "        std_dev = math.sqrt(variance)\n",
    "        cv = std_dev / max(mean_len, 1)\n",
    "        ai_score = max(0, 1 - (cv / 0.6))\n",
    "        \n",
    "        return ai_score, {\n",
    "            'variance': round(variance, 2),\n",
    "            'std_deviation': round(std_dev, 2),\n",
    "            'coefficient_of_variation': round(cv, 3),\n",
    "            'mean_sentence_length': round(mean_len, 1),\n",
    "            'sentence_count': len(sentences),\n",
    "            'description': 'Low burstiness indicates uniform AI-generated patterns'\n",
    "        }\n",
    "    \n",
    "    def detect_citation_hallucination(self, text: str) -> Tuple[float, Dict]:\n",
    "        \"\"\"Detect potentially hallucinated citations.\"\"\"\n",
    "        suspicious_matches = []\n",
    "        \n",
    "        for pattern in self.suspicious_citation_patterns:\n",
    "            found = re.findall(pattern, text, re.IGNORECASE)\n",
    "            suspicious_matches.extend(found)\n",
    "        \n",
    "        all_citations = re.findall(r'\\([A-Z][a-z]+.*?\\d{4}\\)', text)\n",
    "        all_citations += re.findall(r'\\[\\d+\\]', text)\n",
    "        \n",
    "        total_citations = len(all_citations)\n",
    "        suspicious_count = len(suspicious_matches)\n",
    "        \n",
    "        if total_citations == 0:\n",
    "            return 0.5, {\n",
    "                'suspicious_count': 0,\n",
    "                'total_citations': 0,\n",
    "                'examples': [],\n",
    "                'description': 'No citations found - unusual for scholarly paper'\n",
    "            }\n",
    "        \n",
    "        ratio = suspicious_count / max(total_citations, 1)\n",
    "        score = min(1.0, ratio * 2)\n",
    "        \n",
    "        return score, {\n",
    "            'suspicious_count': suspicious_count,\n",
    "            'total_citations': total_citations,\n",
    "            'suspicious_ratio': round(ratio, 3),\n",
    "            'examples': suspicious_matches[:5],\n",
    "            'description': 'Potentially fabricated or hallucinated citations'\n",
    "        }\n",
    "    \n",
    "    def estimate_perplexity(self, text: str) -> Tuple[float, Dict]:\n",
    "        \"\"\"Estimate text perplexity using n-gram frequency analysis.\"\"\"\n",
    "        words = text.lower().split()\n",
    "        \n",
    "        if len(words) < 10:\n",
    "            return 0.0, {'estimated_perplexity': 0, 'description': 'Insufficient text'}\n",
    "        \n",
    "        # Calculate word frequency entropy as proxy for perplexity\n",
    "        word_freq = Counter(words)\n",
    "        total = len(words)\n",
    "        entropy = -sum((count/total) * math.log2(count/total) for count in word_freq.values())\n",
    "        \n",
    "        # Bigram repetition (low variety = AI-like)\n",
    "        bigrams = [f\"{words[i]} {words[i+1]}\" for i in range(len(words)-1)]\n",
    "        bigram_freq = Counter(bigrams)\n",
    "        unique_bigram_ratio = len(bigram_freq) / max(len(bigrams), 1)\n",
    "        \n",
    "        # Low entropy + low bigram variety = AI-like\n",
    "        max_entropy = math.log2(len(word_freq)) if len(word_freq) > 1 else 1\n",
    "        normalized_entropy = entropy / max(max_entropy, 1)\n",
    "        \n",
    "        # Combined score (inverse - low perplexity = high AI score)\n",
    "        perplexity_proxy = (normalized_entropy + unique_bigram_ratio) / 2\n",
    "        ai_score = max(0, 1 - perplexity_proxy)\n",
    "        \n",
    "        return ai_score, {\n",
    "            'word_entropy': round(entropy, 3),\n",
    "            'normalized_entropy': round(normalized_entropy, 3),\n",
    "            'unique_bigram_ratio': round(unique_bigram_ratio, 3),\n",
    "            'vocabulary_size': len(word_freq),\n",
    "            'estimated_perplexity': round(2 ** entropy, 2),\n",
    "            'description': 'Lower perplexity suggests more predictable AI text'\n",
    "        }\n",
    "    \n",
    "    def _calculate_composite_score(self, gpt, gemini, claude, burstiness, citation, perplexity):\n",
    "        \"\"\"Calculate weighted composite GenAI score.\"\"\"\n",
    "        weights = {\n",
    "            'gpt': 0.2,\n",
    "            'gemini': 0.15,\n",
    "            'claude': 0.15,\n",
    "            'burstiness': 0.2,\n",
    "            'citation': 0.1,\n",
    "            'perplexity': 0.2\n",
    "        }\n",
    "        \n",
    "        composite = (\n",
    "            gpt * weights['gpt'] +\n",
    "            gemini * weights['gemini'] +\n",
    "            claude * weights['claude'] +\n",
    "            burstiness * weights['burstiness'] +\n",
    "            citation * weights['citation'] +\n",
    "            perplexity * weights['perplexity']\n",
    "        )\n",
    "        \n",
    "        return min(1.0, composite)\n",
    "    \n",
    "    def _generate_interpretation(self, gpt, gemini, claude, burstiness, citation, perplexity):\n",
    "        \"\"\"Generate human-readable interpretation of scores.\"\"\"\n",
    "        interpretations = []\n",
    "        \n",
    "        if gpt > 0.5:\n",
    "            interpretations.append(\"High frequency of GPT-style formulaic phrases detected\")\n",
    "        if gemini > 0.5:\n",
    "            interpretations.append(\"Over-explanation patterns suggest Gemini-style generation\")\n",
    "        if claude > 0.5:\n",
    "            interpretations.append(\"Significant hedging language indicates possible Claude generation\")\n",
    "        if burstiness > 0.5:\n",
    "            interpretations.append(\"Uniform sentence structure suggests AI-generated content\")\n",
    "        if citation > 0.5:\n",
    "            interpretations.append(\"Some citations appear potentially fabricated\")\n",
    "        if perplexity > 0.5:\n",
    "            interpretations.append(\"Predictable text patterns indicate possible AI generation\")\n",
    "        \n",
    "        if not interpretations:\n",
    "            interpretations.append(\"Text shows natural human writing characteristics\")\n",
    "        \n",
    "        return interpretations\n",
    "    \n",
    "    def _empty_features(self):\n",
    "        \"\"\"Return empty feature dict for invalid input.\"\"\"\n",
    "        return {\n",
    "            'composite_score': 0.0,\n",
    "            'features': {},\n",
    "            'interpretation': ['No text provided for analysis']\n",
    "        }\n",
    "\n",
    "\n",
    "# Create singleton instance\n",
    "extractor = GenAIFeatureExtractor()\n",
    "\n",
    "def extract_genai_features(text: str) -> Dict[str, Any]:\n",
    "    \"\"\"Convenience function to extract GenAI features.\"\"\"\n",
    "    return extractor.extract_all_features(text)\n",
    "\n",
    "print(\"‚úÖ GenAI Feature Extractor loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86491926",
   "metadata": {},
   "source": [
    "## 3. Explainer Chatbot Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b35e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class ExplainerChatbot:\n",
    "    \"\"\"\n",
    "    An explainable AI chatbot for interpreting detection results.\n",
    "    \n",
    "    ETHICAL GUIDELINES:\n",
    "    - Only explains detection results\n",
    "    - Does not generate academic content\n",
    "    - Encourages academic integrity\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the chatbot with response templates.\"\"\"\n",
    "        \n",
    "        self.ethical_disclaimer = (\n",
    "            \"I'm an assistant designed to explain AI detection results. \"\n",
    "            \"I cannot help generate academic content or assist in bypassing detection.\"\n",
    "        )\n",
    "        \n",
    "        # Intent patterns\n",
    "        self.intent_patterns = {\n",
    "            'explain_score': [\n",
    "                r'(what|explain|tell me about).*(score|result|analysis)',\n",
    "                r'(why|how).*(score|detected|flagged)',\n",
    "                r'(mean|meaning|interpret).*(score|result|number)',\n",
    "            ],\n",
    "            'explain_feature': [\n",
    "                r'(what is|explain|tell me about).*(perplexity|burstiness)',\n",
    "                r'(what is|explain).*(gpt|gemini|claude).*(pattern|detection)',\n",
    "                r'(what|explain).*(citation|hallucination)',\n",
    "                r'(what|explain).*(repetition|hedging|overflow)',\n",
    "            ],\n",
    "            'improve_writing': [\n",
    "                r'(how|can I|should I).*(improve|fix|change|rewrite)',\n",
    "                r'(make|write).*(more human|less ai|better)',\n",
    "                r'(tips|advice|suggestions).*(writing|improve)',\n",
    "            ],\n",
    "            'methodology': [\n",
    "                r'(how|what).*(detect|work|algorithm|method)',\n",
    "                r'(explain|tell me about).*(system|detection|process)',\n",
    "            ],\n",
    "            'decision': [\n",
    "                r'(why|explain).*(accept|reject|review)',\n",
    "                r'(what|mean).*(decision|recommendation)',\n",
    "            ],\n",
    "            'greeting': [r'^(hi|hello|hey|greetings)', r'(how are you)'],\n",
    "            'thanks': [r'(thank|thanks|appreciate)'],\n",
    "            'help': [r'(help|assist|support)', r'(what can you|can you help)'],\n",
    "            'unethical_request': [\n",
    "                r'(generate|write|create).*(paper|essay|content)',\n",
    "                r'(bypass|avoid|trick|fool).*(detection|system)',\n",
    "                r'(make|help).*(undetectable|pass)',\n",
    "            ],\n",
    "        }\n",
    "        \n",
    "        # Feature explanations\n",
    "        self.feature_explanations = {\n",
    "            'gpt_repetition': {\n",
    "                'name': 'GPT-Style Repetition',\n",
    "                'description': (\n",
    "                    \"GPT models often use formulaic academic phrases like 'In conclusion', \"\n",
    "                    \"'It is important to note', or 'As mentioned earlier'. High repetition \"\n",
    "                    \"of these patterns suggests AI generation.\"\n",
    "                ),\n",
    "            },\n",
    "            'gemini_overflow': {\n",
    "                'name': 'Gemini Explanatory Overflow',\n",
    "                'description': (\n",
    "                    \"Gemini-style AI often over-explains concepts using phrases like \"\n",
    "                    \"'Let me explain', 'In other words', or 'To elaborate further'.\"\n",
    "                ),\n",
    "            },\n",
    "            'claude_hedging': {\n",
    "                'name': 'Claude Uncertainty Hedging',\n",
    "                'description': (\n",
    "                    \"Claude-style AI frequently uses hedging language like 'perhaps', \"\n",
    "                    \"'possibly', 'it seems', or 'I think'.\"\n",
    "                ),\n",
    "            },\n",
    "            'burstiness': {\n",
    "                'name': 'Burstiness (Sentence Variation)',\n",
    "                'description': (\n",
    "                    \"Burstiness measures variation in sentence length. Human writing typically \"\n",
    "                    \"has high burstiness (varied sentence lengths), while AI text is more uniform.\"\n",
    "                ),\n",
    "            },\n",
    "            'citation_hallucination': {\n",
    "                'name': 'Citation Hallucination Detection',\n",
    "                'description': (\n",
    "                    \"AI models sometimes generate fake citations with generic author names \"\n",
    "                    \"or implausible publication dates.\"\n",
    "                ),\n",
    "            },\n",
    "            'perplexity': {\n",
    "                'name': 'Perplexity (Text Predictability)',\n",
    "                'description': (\n",
    "                    \"Perplexity measures how predictable the text is. AI-generated text \"\n",
    "                    \"typically has lower perplexity (more predictable word choices).\"\n",
    "                ),\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        self.decision_explanations = {\n",
    "            'Accept': \"The paper appears predominantly human-written with minimal AI markers.\",\n",
    "            'Review Needed': \"Mixed signals detected - requires human review.\",\n",
    "            'Reject': \"Strong indicators of AI generation across multiple metrics.\",\n",
    "        }\n",
    "        \n",
    "        self.context = {'last_analysis': None, 'conversation_history': []}\n",
    "    \n",
    "    def set_analysis_context(self, analysis_result: Dict[str, Any]) -> None:\n",
    "        \"\"\"Set the current analysis result for context-aware responses.\"\"\"\n",
    "        self.context['last_analysis'] = analysis_result\n",
    "    \n",
    "    def get_response(self, user_message: str, analysis_result: Optional[Dict] = None) -> Dict[str, Any]:\n",
    "        \"\"\"Generate a response to the user's message.\"\"\"\n",
    "        if analysis_result:\n",
    "            self.set_analysis_context(analysis_result)\n",
    "        \n",
    "        intent = self._detect_intent(user_message)\n",
    "        response = self._generate_response(intent, user_message)\n",
    "        \n",
    "        self.context['conversation_history'].append({\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'user_message': user_message,\n",
    "            'intent': intent,\n",
    "            'response': response['message']\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def _detect_intent(self, message: str) -> str:\n",
    "        \"\"\"Detect the user's intent from their message.\"\"\"\n",
    "        message_lower = message.lower().strip()\n",
    "        \n",
    "        for intent, patterns in self.intent_patterns.items():\n",
    "            for pattern in patterns:\n",
    "                if re.search(pattern, message_lower):\n",
    "                    return intent\n",
    "        \n",
    "        return 'general_query'\n",
    "    \n",
    "    def _generate_response(self, intent: str, message: str) -> Dict[str, Any]:\n",
    "        \"\"\"Generate response based on detected intent.\"\"\"\n",
    "        \n",
    "        handlers = {\n",
    "            'unethical_request': self._respond_to_unethical_request,\n",
    "            'greeting': self._respond_to_greeting,\n",
    "            'thanks': self._respond_to_thanks,\n",
    "            'help': self._respond_to_help,\n",
    "            'explain_score': self._explain_overall_score,\n",
    "            'explain_feature': lambda: self._explain_specific_feature(message),\n",
    "            'improve_writing': self._provide_writing_tips,\n",
    "            'methodology': self._explain_methodology,\n",
    "            'decision': self._explain_decision,\n",
    "        }\n",
    "        \n",
    "        handler = handlers.get(intent, self._respond_to_general_query)\n",
    "        return handler() if callable(handler) else handler\n",
    "    \n",
    "    def _respond_to_unethical_request(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'message': (\n",
    "                \"‚ùå I cannot assist with that request. My purpose is to explain AI detection \"\n",
    "                \"results, not to help bypass detection or generate academic content.\\n\\n\"\n",
    "                \"Academic integrity is important for developing your critical thinking skills \"\n",
    "                \"and earning credentials that reflect your abilities.\"\n",
    "            ),\n",
    "            'type': 'ethical_warning',\n",
    "            'intent': 'unethical_request'\n",
    "        }\n",
    "    \n",
    "    def _respond_to_greeting(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'message': (\n",
    "                \"üëã Hello! I'm your AI Detection Explainer Assistant. I can help you understand:\\n\\n\"\n",
    "                \"‚Ä¢ Your paper's detection scores and what they mean\\n\"\n",
    "                \"‚Ä¢ Specific features like perplexity, burstiness, and pattern detection\\n\"\n",
    "                \"‚Ä¢ Why your paper received a particular decision\\n\"\n",
    "                \"‚Ä¢ How our detection methodology works\\n\\n\"\n",
    "                \"What would you like to know?\"\n",
    "            ),\n",
    "            'type': 'greeting',\n",
    "            'intent': 'greeting'\n",
    "        }\n",
    "    \n",
    "    def _respond_to_thanks(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'message': \"You're welcome! Feel free to ask if you have more questions.\",\n",
    "            'type': 'acknowledgment',\n",
    "            'intent': 'thanks'\n",
    "        }\n",
    "    \n",
    "    def _respond_to_help(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'message': (\n",
    "                \"üÜò I can help you understand your AI detection analysis:\\n\\n\"\n",
    "                \"**About Scores:**\\n\"\n",
    "                \"‚Ä¢ 'Explain my scores'\\n\"\n",
    "                \"‚Ä¢ 'Why was my paper flagged?'\\n\\n\"\n",
    "                \"**About Features:**\\n\"\n",
    "                \"‚Ä¢ 'What is perplexity?'\\n\"\n",
    "                \"‚Ä¢ 'Explain burstiness'\\n\"\n",
    "                \"‚Ä¢ 'What is GPT-style repetition?'\\n\\n\"\n",
    "                \"**About Improvement:**\\n\"\n",
    "                \"‚Ä¢ 'How can I improve my writing?'\"\n",
    "            ),\n",
    "            'type': 'help',\n",
    "            'intent': 'help'\n",
    "        }\n",
    "    \n",
    "    def _explain_overall_score(self) -> Dict[str, Any]:\n",
    "        analysis = self.context.get('last_analysis')\n",
    "        \n",
    "        if not analysis:\n",
    "            return {\n",
    "                'message': \"I don't have an analysis result. Please analyze a text first!\",\n",
    "                'type': 'no_context',\n",
    "                'intent': 'explain_score'\n",
    "            }\n",
    "        \n",
    "        genai = analysis.get('genai_features', {})\n",
    "        composite = genai.get('composite_score', 0)\n",
    "        features = genai.get('features', {})\n",
    "        interpretation = genai.get('interpretation', [])\n",
    "        \n",
    "        message = f\"üìä **Analysis Summary**\\n\\n\"\n",
    "        message += f\"**Composite AI Score:** {composite:.1%}\\n\\n\"\n",
    "        message += \"**Feature Breakdown:**\\n\"\n",
    "        \n",
    "        for name, data in features.items():\n",
    "            score = data.get('score', 0)\n",
    "            level = \"High\" if score > 0.6 else \"Moderate\" if score > 0.3 else \"Low\"\n",
    "            readable_name = name.replace('_', ' ').title()\n",
    "            message += f\"‚Ä¢ {readable_name}: {level} ({score:.1%})\\n\"\n",
    "        \n",
    "        if interpretation:\n",
    "            message += \"\\n**Key Findings:**\\n\"\n",
    "            for interp in interpretation[:3]:\n",
    "                message += f\"‚Ä¢ {interp}\\n\"\n",
    "        \n",
    "        return {\n",
    "            'message': message,\n",
    "            'type': 'score_explanation',\n",
    "            'intent': 'explain_score'\n",
    "        }\n",
    "    \n",
    "    def _explain_specific_feature(self, message: str) -> Dict[str, Any]:\n",
    "        message_lower = message.lower()\n",
    "        \n",
    "        feature_key = None\n",
    "        if 'perplexity' in message_lower:\n",
    "            feature_key = 'perplexity'\n",
    "        elif 'burstiness' in message_lower or 'burst' in message_lower:\n",
    "            feature_key = 'burstiness'\n",
    "        elif 'gpt' in message_lower or 'repetition' in message_lower:\n",
    "            feature_key = 'gpt_repetition'\n",
    "        elif 'gemini' in message_lower or 'overflow' in message_lower:\n",
    "            feature_key = 'gemini_overflow'\n",
    "        elif 'claude' in message_lower or 'hedging' in message_lower:\n",
    "            feature_key = 'claude_hedging'\n",
    "        elif 'citation' in message_lower or 'hallucination' in message_lower:\n",
    "            feature_key = 'citation_hallucination'\n",
    "        \n",
    "        if feature_key and feature_key in self.feature_explanations:\n",
    "            feature = self.feature_explanations[feature_key]\n",
    "            return {\n",
    "                'message': f\"üìñ **{feature['name']}**\\n\\n{feature['description']}\",\n",
    "                'type': 'feature_explanation',\n",
    "                'intent': 'explain_feature'\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            'message': (\n",
    "                \"I can explain these features:\\n\"\n",
    "                \"‚Ä¢ Perplexity\\n‚Ä¢ Burstiness\\n‚Ä¢ GPT Repetition\\n\"\n",
    "                \"‚Ä¢ Gemini Overflow\\n‚Ä¢ Claude Hedging\\n‚Ä¢ Citation Hallucination\"\n",
    "            ),\n",
    "            'type': 'clarification',\n",
    "            'intent': 'explain_feature'\n",
    "        }\n",
    "    \n",
    "    def _provide_writing_tips(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'message': (\n",
    "                \"‚úçÔ∏è **Tips for More Natural Writing:**\\n\\n\"\n",
    "                \"1. **Vary sentence length** - Mix short, punchy sentences with longer ones\\n\"\n",
    "                \"2. **Use personal voice** - Develop your unique writing style\\n\"\n",
    "                \"3. **Avoid formulaic phrases** - Skip 'In conclusion', 'It is important to note'\\n\"\n",
    "                \"4. **Be direct** - Don't over-explain or hedge excessively\\n\"\n",
    "                \"5. **Verify citations** - Ensure all references are real and accurate\\n\"\n",
    "                \"6. **Read aloud** - Natural writing flows when spoken\\n\\n\"\n",
    "                \"Remember: The goal is authentic expression, not detection avoidance!\"\n",
    "            ),\n",
    "            'type': 'writing_tips',\n",
    "            'intent': 'improve_writing'\n",
    "        }\n",
    "    \n",
    "    def _explain_methodology(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'message': (\n",
    "                \"üî¨ **How Detection Works:**\\n\\n\"\n",
    "                \"Our system analyzes text using multiple methods:\\n\\n\"\n",
    "                \"1. **Pattern Matching** - Detects phrases typical of GPT, Gemini, and Claude\\n\"\n",
    "                \"2. **Burstiness Analysis** - Measures sentence length variation\\n\"\n",
    "                \"3. **Perplexity Estimation** - Assesses text predictability\\n\"\n",
    "                \"4. **Citation Analysis** - Checks for potentially hallucinated references\\n\\n\"\n",
    "                \"All features are weighted and combined into a composite score.\"\n",
    "            ),\n",
    "            'type': 'methodology',\n",
    "            'intent': 'methodology'\n",
    "        }\n",
    "    \n",
    "    def _explain_decision(self) -> Dict[str, Any]:\n",
    "        analysis = self.context.get('last_analysis')\n",
    "        \n",
    "        if not analysis:\n",
    "            return {\n",
    "                'message': \"Please analyze a text first to receive a decision.\",\n",
    "                'type': 'no_context',\n",
    "                'intent': 'decision'\n",
    "            }\n",
    "        \n",
    "        composite = analysis.get('genai_features', {}).get('composite_score', 0)\n",
    "        \n",
    "        if composite < 0.3:\n",
    "            decision, explanation = 'Accept', self.decision_explanations['Accept']\n",
    "        elif composite < 0.6:\n",
    "            decision, explanation = 'Review Needed', self.decision_explanations['Review Needed']\n",
    "        else:\n",
    "            decision, explanation = 'Reject', self.decision_explanations['Reject']\n",
    "        \n",
    "        return {\n",
    "            'message': f\"üìã **Decision: {decision}**\\n\\n{explanation}\\n\\nComposite Score: {composite:.1%}\",\n",
    "            'type': 'decision_explanation',\n",
    "            'intent': 'decision'\n",
    "        }\n",
    "    \n",
    "    def _respond_to_general_query(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'message': (\n",
    "                \"I can help you with:\\n\"\n",
    "                \"‚Ä¢ Explaining scores - 'Explain my results'\\n\"\n",
    "                \"‚Ä¢ Understanding features - 'What is perplexity?'\\n\"\n",
    "                \"‚Ä¢ Decision explanation - 'Why was my paper flagged?'\\n\"\n",
    "                \"‚Ä¢ Writing improvement - 'How can I improve my writing?'\\n\\n\"\n",
    "                \"Could you rephrase your question?\"\n",
    "            ),\n",
    "            'type': 'clarification',\n",
    "            'intent': 'general_query'\n",
    "        }\n",
    "    \n",
    "    def generate_automatic_explanation(self, analysis_result: Dict[str, Any]) -> str:\n",
    "        \"\"\"Generate an automatic explanation when analysis completes.\"\"\"\n",
    "        self.set_analysis_context(analysis_result)\n",
    "        \n",
    "        genai = analysis_result.get('genai_features', {})\n",
    "        composite = genai.get('composite_score', 0)\n",
    "        \n",
    "        if composite < 0.3:\n",
    "            intro = \"‚úÖ Great news! Your text appears predominantly human-written.\"\n",
    "        elif composite < 0.6:\n",
    "            intro = \"‚ö†Ô∏è Your text shows some AI-like patterns and may need review.\"\n",
    "        else:\n",
    "            intro = \"üö® This text shows significant AI-generated characteristics.\"\n",
    "        \n",
    "        explanation = f\"{intro}\\n\\n\"\n",
    "        explanation += f\"**AI Score:** {composite:.1%}\\n\\n\"\n",
    "        \n",
    "        if genai.get('interpretation'):\n",
    "            explanation += \"**Key Findings:**\\n\"\n",
    "            for interp in genai.get('interpretation', [])[:3]:\n",
    "                explanation += f\"‚Ä¢ {interp}\\n\"\n",
    "        \n",
    "        explanation += \"\\nüí¨ Ask me anything about these results!\"\n",
    "        \n",
    "        return explanation\n",
    "\n",
    "\n",
    "# Singleton instance\n",
    "_chatbot_instance = None\n",
    "\n",
    "def get_chatbot() -> ExplainerChatbot:\n",
    "    global _chatbot_instance\n",
    "    if _chatbot_instance is None:\n",
    "        _chatbot_instance = ExplainerChatbot()\n",
    "    return _chatbot_instance\n",
    "\n",
    "def chat(message: str, analysis_result: Optional[Dict] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Convenience function for chatbot interaction.\"\"\"\n",
    "    return get_chatbot().get_response(message, analysis_result)\n",
    "\n",
    "def generate_explanation(analysis_result: Dict[str, Any]) -> str:\n",
    "    \"\"\"Generate automatic explanation for analysis result.\"\"\"\n",
    "    return get_chatbot().generate_automatic_explanation(analysis_result)\n",
    "\n",
    "print(\"‚úÖ Explainer Chatbot loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888b4e21",
   "metadata": {},
   "source": [
    "## 4. Interactive Demo Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0537b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "def analyze_text(text: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyze text and return combined features with chatbot explanation.\n",
    "    \"\"\"\n",
    "    # Extract GenAI features\n",
    "    genai_features = extract_genai_features(text)\n",
    "    \n",
    "    # Build analysis result\n",
    "    analysis_result = {\n",
    "        'genai_features': genai_features,\n",
    "        'text_length': len(text),\n",
    "        'word_count': len(text.split())\n",
    "    }\n",
    "    \n",
    "    # Generate chatbot explanation\n",
    "    explanation = generate_explanation(analysis_result)\n",
    "    analysis_result['chatbot_explanation'] = explanation\n",
    "    \n",
    "    return analysis_result\n",
    "\n",
    "\n",
    "def display_analysis_results(results: Dict[str, Any]):\n",
    "    \"\"\"Display analysis results in a formatted way.\"\"\"\n",
    "    genai = results.get('genai_features', {})\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"üìä GENAI DETECTION ANALYSIS RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    composite = genai.get('composite_score', 0)\n",
    "    print(f\"\\nüéØ Composite AI Score: {composite:.1%}\")\n",
    "    \n",
    "    # Decision\n",
    "    if composite < 0.3:\n",
    "        print(\"‚úÖ Decision: ACCEPT (Likely Human-Written)\")\n",
    "    elif composite < 0.6:\n",
    "        print(\"‚ö†Ô∏è Decision: REVIEW NEEDED (Mixed Signals)\")\n",
    "    else:\n",
    "        print(\"üö® Decision: REJECT (Likely AI-Generated)\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 60)\n",
    "    print(\"üìà FEATURE BREAKDOWN\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    features = genai.get('features', {})\n",
    "    for name, data in features.items():\n",
    "        score = data.get('score', 0)\n",
    "        level = \"üî¥ High\" if score > 0.6 else \"üü° Moderate\" if score > 0.3 else \"üü¢ Low\"\n",
    "        readable_name = name.replace('_', ' ').title()\n",
    "        print(f\"  {readable_name:25s}: {score:.1%} ({level})\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 60)\n",
    "    print(\"üí° KEY INTERPRETATIONS\")\n",
    "    print(\"-\" * 60)\n",
    "    for interp in genai.get('interpretation', []):\n",
    "        print(f\"  ‚Ä¢ {interp}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ü§ñ CHATBOT EXPLANATION\")\n",
    "    print(\"=\" * 60)\n",
    "    print(results.get('chatbot_explanation', 'No explanation available.'))\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "print(\"‚úÖ Demo functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc44449",
   "metadata": {},
   "source": [
    "## 5. Test with Sample Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1559a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample AI-Generated Text (GPT-style)\n",
    "ai_sample = \"\"\"\n",
    "In conclusion, it is important to note that artificial intelligence has revolutionized \n",
    "the way we approach complex problems. As mentioned earlier, this demonstrates that \n",
    "machine learning plays a crucial role in modern data analysis. It can be argued that \n",
    "these advancements have significant implications for various industries.\n",
    "\n",
    "The fact that deep learning models can process vast amounts of data shows that \n",
    "computational power has increased dramatically. In this context, it is worth noting \n",
    "that neural networks have become increasingly sophisticated. This paper aims to \n",
    "explore these developments in detail.\n",
    "\n",
    "According to Smith et al. (2027), the future of AI looks promising. Research by \n",
    "Johnson et al. (2026) suggests that automation will continue to expand. The study \n",
    "by Williams et al. (2028) indicates significant growth in this sector.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"#\" * 60)\n",
    "print(\"# ANALYZING AI-GENERATED SAMPLE TEXT\")\n",
    "print(\"#\" * 60)\n",
    "\n",
    "results = analyze_text(ai_sample)\n",
    "display_analysis_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5350b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Human-Written Text (more natural variation)\n",
    "human_sample = \"\"\"\n",
    "Machine learning has changed everything. Or at least, that's what the headlines say.\n",
    "\n",
    "But what does it actually mean for researchers? The algorithms that power recommendation \n",
    "systems on Netflix are fundamentally different from those analyzing medical images. \n",
    "Some work brilliantly. Others fail spectacularly.\n",
    "\n",
    "I've spent three years studying computer vision applications in radiology departments \n",
    "across five hospitals. The results surprised me. Despite all the hype, only 23% of \n",
    "radiologists reported daily AI tool usage. Cost was a factor, sure. But trust was bigger.\n",
    "\n",
    "Dr. Sarah Chen at Mass General put it best: \"These systems work great in the lab. \n",
    "Real patients are messier.\" She's not wrong.\n",
    "\n",
    "The data from our study (n=847) shows clear patterns. Urban hospitals adopted faster. \n",
    "Rural facilities lagged by 18 months on average. Money wasn't always the problem.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"#\" * 60)\n",
    "print(\"# ANALYZING HUMAN-WRITTEN SAMPLE TEXT\")\n",
    "print(\"#\" * 60)\n",
    "\n",
    "results = analyze_text(human_sample)\n",
    "display_analysis_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305897c4",
   "metadata": {},
   "source": [
    "## 6. Interactive Chatbot Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328967fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Chatbot\n",
    "print(\"=\" * 60)\n",
    "print(\"ü§ñ INTERACTIVE CHATBOT DEMO\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Type your questions about AI detection!\")\n",
    "print(\"Example queries:\")\n",
    "print(\"  ‚Ä¢ 'Hello'\")\n",
    "print(\"  ‚Ä¢ 'Explain my scores'\")\n",
    "print(\"  ‚Ä¢ 'What is perplexity?'\")\n",
    "print(\"  ‚Ä¢ 'How does detection work?'\")\n",
    "print(\"  ‚Ä¢ 'Tips for better writing'\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test various chatbot interactions\n",
    "test_messages = [\n",
    "    \"Hello!\",\n",
    "    \"What is perplexity?\",\n",
    "    \"Explain my scores\",\n",
    "    \"How can I improve my writing?\"\n",
    "]\n",
    "\n",
    "for msg in test_messages:\n",
    "    print(f\"\\nüë§ User: {msg}\")\n",
    "    response = chat(msg, results)  # Pass the last analysis for context\n",
    "    print(f\"\\nü§ñ Bot: {response['message']}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e4a305",
   "metadata": {},
   "source": [
    "## 7. Analyze Your Own Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbc5ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úèÔ∏è PASTE YOUR TEXT HERE!\n",
    "your_text = \"\"\"\n",
    "Paste your text here to analyze it for AI-generated content.\n",
    "The system will check for patterns typical of GPT, Gemini, and Claude,\n",
    "as well as analyze burstiness, perplexity, and citation quality.\n",
    "\"\"\"\n",
    "\n",
    "# Analyze\n",
    "print(\"\\n\" + \"#\" * 60)\n",
    "print(\"# ANALYZING YOUR TEXT\")\n",
    "print(\"#\" * 60)\n",
    "\n",
    "my_results = analyze_text(your_text)\n",
    "display_analysis_results(my_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430d0f37",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a278c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive chat about your results\n",
    "print(\"\\nüí¨ Ask questions about your analysis:\")\n",
    "\n",
    "# Ask the chatbot about your specific results\n",
    "your_question = \"Explain my scores\"  # ‚úèÔ∏è Change this to your question!\n",
    "\n",
    "response = chat(your_question, my_results)\n",
    "print(f\"\\nüë§ You: {your_question}\")\n",
    "print(f\"\\nü§ñ Bot: {response['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef97303",
   "metadata": {},
   "source": [
    "## 8. Interactive Chat Loop (Run Multiple Times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c02bb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell multiple times to have a conversation!\n",
    "# Change the question each time.\n",
    "\n",
    "question = \"What is burstiness?\"  # ‚úèÔ∏è Edit this question!\n",
    "\n",
    "response = chat(question, my_results)\n",
    "print(f\"üë§ You: {question}\")\n",
    "print(f\"\\nü§ñ Bot: {response['message']}\")\n",
    "print(f\"\\n[Intent detected: {response['intent']}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7127ab6d",
   "metadata": {},
   "source": [
    "## 9. Feature Detail Viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac052d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_details(feature_name: str, results: Dict[str, Any]):\n",
    "    \"\"\"Show detailed information about a specific feature.\"\"\"\n",
    "    features = results.get('genai_features', {}).get('features', {})\n",
    "    \n",
    "    if feature_name not in features:\n",
    "        print(f\"Feature '{feature_name}' not found.\")\n",
    "        print(f\"Available: {list(features.keys())}\")\n",
    "        return\n",
    "    \n",
    "    feature = features[feature_name]\n",
    "    details = feature.get('details', {})\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"üìã {feature_name.replace('_', ' ').upper()} DETAILS\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"\\nScore: {feature['score']:.1%}\")\n",
    "    print(f\"\\nDetails:\")\n",
    "    for key, value in details.items():\n",
    "        print(f\"  ‚Ä¢ {key}: {value}\")\n",
    "\n",
    "\n",
    "# Show details for each feature\n",
    "for feature_name in ['gpt_repetition', 'gemini_overflow', 'claude_hedging', \n",
    "                      'burstiness', 'perplexity', 'citation_hallucination']:\n",
    "    show_feature_details(feature_name, my_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016686dc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Documentation\n",
    "\n",
    "### Features Detected:\n",
    "\n",
    "| Feature | Description | AI-Like Score |\n",
    "|---------|-------------|---------------|\n",
    "| GPT Repetition | Formulaic phrases like \"In conclusion\", \"It is important to note\" | High = More AI |\n",
    "| Gemini Overflow | Over-explanation patterns like \"Let me explain\", \"In other words\" | High = More AI |\n",
    "| Claude Hedging | Uncertainty language like \"perhaps\", \"possibly\", \"it seems\" | High = More AI |\n",
    "| Burstiness | Sentence length variation (humans vary more) | High = More AI |\n",
    "| Perplexity | Text predictability (AI is more predictable) | High = More AI |\n",
    "| Citation Hallucination | Potentially fabricated references | High = Suspicious |\n",
    "\n",
    "### Decision Thresholds:\n",
    "\n",
    "| Composite Score | Decision |\n",
    "|-----------------|----------|\n",
    "| < 30% | ‚úÖ Accept (Likely Human) |\n",
    "| 30-60% | ‚ö†Ô∏è Review Needed |\n",
    "| > 60% | üö® Reject (Likely AI) |\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** AI-Generated Scholarly Paper Detection System  \n",
    "**For Academic Use Only - IEEE/College-level Project**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
